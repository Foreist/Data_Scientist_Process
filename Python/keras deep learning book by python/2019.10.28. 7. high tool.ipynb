{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2019.10.28. 7. high tool.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EwbbCChlui6w","colab_type":"code","outputId":"eebc384f-f963-4236-a287-e941608df747","executionInfo":{"status":"ok","timestamp":1572322896575,"user_tz":-540,"elapsed":1382,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"}},"colab":{"base_uri":"https://localhost:8080/","height":563}},"source":["# sequential와 함수형 api로 모델을 동일하게 만들어 보기\n","from keras.models import Sequential, Model\n","from keras import layers\n","from keras import Input\n","\n","seq_model = Sequential()\n","seq_model.add(layers.Dense(32, activation = 'relu', input_shape = (64,)))\n","seq_model.add(layers.Dense(32, activation = 'relu'))\n","seq_model.add(layers.Dense(10, activation = 'softmax'))\n","\n","input_tensor = Input(shape = (64,))\n","x = layers.Dense(32, activation = 'relu')(input_tensor)\n","x = layers.Dense(32, activation = 'relu')(x)\n","output_tensor = layers.Dense(10, activation = 'softmax')(x)\n","\n","model = Model(input_tensor, output_tensor)\n","seq_model.summary()\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_11 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 32)                1056      \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 10)                330       \n","=================================================================\n","Total params: 3,466\n","Trainable params: 3,466\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 64)                0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 32)                1056      \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 10)                330       \n","=================================================================\n","Total params: 3,466\n","Trainable params: 3,466\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6zitDB-kvq_K","colab_type":"code","colab":{}},"source":["# 질문-응답 모델의 함수형 api 구현하기\n","\n","from keras.models import Model\n","from keras import layers\n","from keras import Input\n","\n","text_vocabulary_size = 10000\n","question_vocabulary_size = 10000\n","answer_vocabulary_size = 500\n","\n","# 텍스트 입력은 길이가 정해지지 않은 정수 시퀀스임.\n","text_input = Input(shape = (None,), dtype = 'int32', name = 'text')\n","\n","# 입력을 크기가 64인 벡터의 시퀀스로 임베딩\n","embedded_text = layers.Embedding(\n","    text_vocabulary_size, 64)(text_input)\n","\n","# LSTM을 사용해서 이 벡터들을 하나의 벡터로 인코딩\n","encoded_text = layers.LSTM(32)(embedded_text)\n","\n","# 질문 입력은 길이가 정해지지 않은 정수 시퀀스임.\n","question_input = Input(shape = (None,), dtype = 'int32', name = 'question')\n","\n","# 질문을 크기가 64인 벡터의 시퀀스로 임베딩\n","embedded_question = layers.Embedding(\n","    question_vocabulary_size, 32)(question_input)\n","\n","encoded_question = layers.LSTM(16)(embedded_question)\n","\n","concatenated = layers.concatenate([encoded_text, encoded_question], axis = -1)\n","\n","answer = layers.Dense(answer_vocabulary_size,\n","                      activation = 'softmax')(concatenated)\n","\n","# 모델 객체 만들고 2개 입, 출력 주입\n","model = Model([text_input, question_input], answer)\n","model.compile(optimizer = 'rmsprop',\n","              loss = 'categorical_crossentropy',\n","              metrics = ['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRhXjzPK7Kfp","colab_type":"code","colab":{}},"source":["#  훈련 방식은 두 가지가 있는데 numpy 배열 리스트를 주입하거나\n","# 입력이름과 넘파이 배열로 이루어진 딕셔너리를 모델로 주입\n","# 후자는 입력이름을 설정했을 때 사용할 수 있음"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HsJHxe6_6lM","colab_type":"code","outputId":"40f9f779-8d95-4d26-da25-b260f8c0298e","executionInfo":{"status":"ok","timestamp":1572327646055,"user_tz":-540,"elapsed":62805,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","from keras.utils import to_categorical\n","\n","num_samples = 1000\n","max_length = 100\n","\n","text = np.random.randint(1, text_vocabulary_size,\n","                         size = (num_samples, max_length))\n","\n","question = np.random.randint(1, question_vocabulary_size,\n","                             size = (num_samples, max_length))\n","\n","answers = np.random.randint(0, answer_vocabulary_size, size = num_samples)\n","\n","answers = to_categorical(answers)\n","model.fit([text, question], answers, epochs = 10, batch_size = 128)\n","\n","model.fit({'text': text, 'question': question}, answers,\n","          epochs = 10, batch_size = 128)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/10\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","1000/1000 [==============================] - 8s 8ms/step - loss: 6.2146 - acc: 1.0000e-03\n","Epoch 2/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 6.1981 - acc: 0.0500\n","Epoch 3/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 6.1446 - acc: 0.0060\n","Epoch 4/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 6.0546 - acc: 0.0050\n","Epoch 5/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.9938 - acc: 0.0070\n","Epoch 6/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.9311 - acc: 0.0080\n","Epoch 7/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.8710 - acc: 0.0080\n","Epoch 8/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.8158 - acc: 0.0100\n","Epoch 9/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.7341 - acc: 0.0110\n","Epoch 10/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.6502 - acc: 0.0200\n","Epoch 1/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.5719 - acc: 0.0240\n","Epoch 2/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.4951 - acc: 0.0220\n","Epoch 3/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.4291 - acc: 0.0320\n","Epoch 4/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.3707 - acc: 0.0400\n","Epoch 5/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.3353 - acc: 0.0450\n","Epoch 6/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.2526 - acc: 0.0500\n","Epoch 7/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.1828 - acc: 0.0620\n","Epoch 8/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.1459 - acc: 0.0650\n","Epoch 9/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.1013 - acc: 0.0780\n","Epoch 10/10\n","1000/1000 [==============================] - 3s 3ms/step - loss: 5.0410 - acc: 0.0760\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f78a1ef88d0>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"Wadt4PX9BfWN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}